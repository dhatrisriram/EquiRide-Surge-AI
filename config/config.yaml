# Data Pipeline Configuration

data:
  input_csv: "datasets/processed_data.csv"
  raw_data_path: "datasets/"
  processed_data_path: "datasets/"
  features_path: "datasets/"
  feature_store_path: "datasets/feature_store/surge_features.db"

features:
  time_buckets_minutes: 15
  rolling_window_sizes: [3, 6, 12, 24]
  lag_periods: [1, 3, 6, 12]
  anomaly_threshold: 2.5

spatial:
  h3_resolution: 9
  key_zones:
    - "whitefield"
    - "koramangala"
    - "indiranagar"
    - "mg_road"
    - "electronic_city"

streaming:
  enabled: true
  batch_size: 50
  interval_minutes: 15
  simulation_mode: true

pipeline:
  run_interval_minutes: 15
  enable_parallel: false
  max_retries: 3

monitoring:
  log_level: "INFO"
  log_file: "logs/pipeline.log"
  max_log_size_mb: 50
  enable_alerts: true

alerts:
  demand_surge_threshold: 2.0
  congestion_threshold: 80.0
  anomaly_confidence_threshold: 0.85
  alert_cooldown_minutes: 30

twilio:
  enabled: true
  send_sms: true
  send_whatsapp: false

data_quality:
  check_missing_values: true
  check_duplicates: true
  check_outliers: true
  outlier_method: "IQR"
  max_missing_pct: 10

feature_store:
  update_mode: "append"
  partition_by: ["h3_index", "date"]
  retention_days: 90
  enable_versioning: true
